{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVjFDYIhDGh2sTe65dv1c0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishik11/DeL-haTE/blob/master/eval_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ElNAxEAZ4ok"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import Counter\n",
        "\n",
        "import utils\n",
        "from model import DelhateEnsemble\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and args.use_gpu else 'cpu')\n",
        "\n",
        "    try:\n",
        "        _, dataset, embed, model_type, model_name = args.model_path.split('/')\n",
        "        model = DelhateEnsemble.load_model(args.model_path)\n",
        "    except FileNotFoundError:\n",
        "        raise\n",
        "\n",
        "    embedding, dim = utils.load_embedding(model.embed_corpus)\n",
        "\n",
        "    test_data = utils.load_dataset(args.dataset, 'test', embedding, labeled=True, pad=model.seq_length)\n",
        "\n",
        "    model.to(device)\n",
        "    y_pred, y_true = model.evaluate(test_data, device=device)\n",
        "\n",
        "    print('pred:', Counter(y_pred))\n",
        "    print('true:', Counter(y_true))\n",
        "\n",
        "    report = classification_report(y_true, y_pred, target_names=['H', 'O', 'N'], digits=3)\n",
        "    conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    model_name = model_name.replace('.pt', '')\n",
        "    out_path = f'metrics/{dataset.upper()}/{embed}/{model_type}'\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    with open(f'{out_path}/{model_name}_{args.dataset}.txt', 'w') as f:\n",
        "        f.write(report)\n",
        "        f.write('\\n')\n",
        "        f.write('\\n'.join('  '.join(str(x) for x in y) for y in conf_mat))\n",
        "        f.write('\\n')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('dataset', type=str,\n",
        "                        help='Dataset on which to evaluate the model. Options are hon/olid/combined/gab')\n",
        "\n",
        "    parser.add_argument('model_path', type=str,\n",
        "                        help='File path for the trained model. See train_model.py for training and saving a model.')\n",
        "\n",
        "    parser.add_argument('--use-gpu', type=bool, default=True,\n",
        "                        help='Use GPU for model training. Default is True.')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}