{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEW0dsbqZ3sN0eacKupQKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishik11/DeL-haTE/blob/master/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6kj4G-vehx7"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import utils\n",
        "from model import DelhateEnsemble\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() and args.use_gpu else 'cpu')\n",
        "\n",
        "    rnn_str = args.rnn_type if args.rnn_type else 'cnn'\n",
        "    weak_str = '_weak' if args.weak_loss else ''\n",
        "\n",
        "    out_path = f'models/{args.dataset}/{args.embed_corpus}/delhate_{rnn_str}{weak_str}'\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    embedding, dim = utils.load_embedding(args.embed_corpus)\n",
        "\n",
        "    labeled = not args.weak_loss\n",
        "\n",
        "    train_data = utils.load_dataset(args.dataset, 'train', embedding, labeled, args.pad)\n",
        "\n",
        "    model = DelhateEnsemble(\n",
        "        n_models=args.n_models,\n",
        "        seq_length=train_data.padded_seq,\n",
        "        embed_corpus=args.embed_corpus,\n",
        "        embed_dim=dim,\n",
        "        n_classes=train_data.n_classes,\n",
        "        n_filters=args.n_filters,\n",
        "        filter_width=args.filter_width,\n",
        "        pool_size=args.pool_size,\n",
        "        n_hidden=args.n_hidden,\n",
        "        rnn_type=args.rnn_type,\n",
        "        dropout=args.dropout\n",
        "    )\n",
        "\n",
        "    if args.weak_loss:\n",
        "        loss_fn = lambda x, y: utils.weak_loss(x, y, weight=args.class_weight)\n",
        "    else:\n",
        "        loss_fn = F.cross_entropy\n",
        "\n",
        "    model.train_models(\n",
        "        train_data,\n",
        "        loss_fn=loss_fn,\n",
        "        lr=args.learn_rate,\n",
        "        n_samples=args.n_samples,\n",
        "        use_val=args.use_val,\n",
        "        early_stop=args.early_stop,\n",
        "        batch_size=args.batch_size,\n",
        "        EPOCHS=args.epochs,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    model.save_model(f'{out_path}/{args.model_name}.pt')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = utils.parse_train_args()\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}